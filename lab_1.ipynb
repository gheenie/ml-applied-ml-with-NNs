{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTKCqiKEto03WaEAYMmXm3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gheenie/msc-applied-ml/blob/main/lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "from google.colab import drive\n",
        "import numpy\n",
        "from numpy import loadtxt\n",
        "# from urllib import urlopen\n",
        "from pandas import read_csv\n",
        "from pandas import set_option\n",
        "from matplotlib import pyplot\n",
        "from pandas.plotting import scatter_matrix\n",
        "from numpy import set_printoptions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import ShuffleSplit\n"
      ],
      "metadata": {
        "id": "eArvgqGpLsRe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount location\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change working dir\n",
        "os.chdir('drive/Colab Notebooks')\n"
      ],
      "metadata": {
        "id": "-3a5VjGFGr8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data\n"
      ],
      "metadata": {
        "id": "XTQZt2UcKfyG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57LggRch-e0-"
      },
      "outputs": [],
      "source": [
        "# Load CSV Using Python Standard Library\n",
        "\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "raw_data = open(filename, 'rt')\n",
        "reader = csv.reader(raw_data, delimiter=',', quoting=csv.QUOTE_NONE)\n",
        "x = list(reader)\n",
        "data = numpy.array(x).astype('float')\n",
        "print(data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV using NumPy\n",
        "\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "raw_data = open(filename, 'rt')\n",
        "data = loadtxt(raw_data, delimiter=\",\")\n",
        "print(data.shape)\n"
      ],
      "metadata": {
        "id": "WiF-RPLiI4Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV from URL using NumPy\n",
        "\n",
        "url = 'https://goo.gl/XXXXX'\n",
        "raw_data = urlopen(url)\n",
        "dataset = loadtxt(raw_data, delimiter=\",\")\n",
        "print(dataset.shape)\n"
      ],
      "metadata": {
        "id": "Fy4H-EZ-JhV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV using Pandas\n",
        "\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "data = read_csv(filename, names=names)\n",
        "print(data.shape)\n"
      ],
      "metadata": {
        "id": "WzZ8rWNIKaw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc8726b-ffb3-4d27-a2fc-179e9c0b2269"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV using Pandas from URL\n",
        "\n",
        "url = 'https://goo.gl/XXXXXXX'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "data = read_csv(url, names=names)\n",
        "print(data.shape)\n"
      ],
      "metadata": {
        "id": "rs89yhlHLHbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descriptive statistics\n"
      ],
      "metadata": {
        "id": "uoR6YUvoNRp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect data\n",
        "\n",
        "# First few rows\n",
        "peek = data.head(20)\n",
        "print(peek)\n",
        "# Data types\n",
        "types = data.dtypes\n",
        "print(types)\n",
        "\n",
        "# Review data dimensions\n",
        "# Too many or few rows or features?\n",
        "\n",
        "shape = data.shape\n",
        "print(shape)\n",
        "\n",
        "# Descriptive stats\n",
        "\n",
        "set_option('display.width', 100)\n",
        "set_option('display.precision', 3)\n",
        "description = data.describe()\n",
        "print(description)\n",
        "\n",
        "# Class distributions (for classification probs)\n",
        "# Need to be balanced\n",
        "\n",
        "class_counts = data.groupby('class').size()\n",
        "print(class_counts)\n",
        "\n",
        "# Pairwise Pearson correlations\n",
        "# Don't want highly correlated pairs\n",
        "\n",
        "correlations = data.corr(method='pearson')\n",
        "print(correlations)\n",
        "\n",
        "# Skew of univariate distributions for each attribute\n",
        "\n",
        "skew = data.skew()\n",
        "print(skew)\n"
      ],
      "metadata": {
        "id": "jlV2q4QRNTWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualisation\n"
      ],
      "metadata": {
        "id": "OYYTstvfA6NO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Univariate plots\n",
        "# Understand each attribute of your dataset independently\n",
        "\n",
        "# Univariate histograms\n",
        "# Get an idea of distributions.\n",
        "# From the shape of the bins you can quickly get a\n",
        "# feeling for whether an attribute is Gaussian, skewed or even has an\n",
        "# exponential distribution. It can also help you see possible outliers.\n",
        "\n",
        "data.hist()\n",
        "pyplot.show()\n",
        "\n",
        "# Univariate density plots\n",
        "# Get an idea of distributions\n",
        "\n",
        "data.plot(kind='density', subplots=True, layout=(3,3), sharex=False)\n",
        "pyplot.show()\n",
        "\n",
        "# Box and whiskers plot\n",
        "# Get an idea of distributions.\n",
        "# Candidate outlier values are 1.5 times greater than the size of spread of\n",
        "# the middle 50% of the data\n",
        "\n",
        "data.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\n",
        "pyplot.show()\n",
        "\n",
        "# Multivariate plots\n",
        "# Show the interactions between multiple variables in your dataset\n",
        "\n",
        "# Correlation matrix plot\n",
        "# Some machine learning algorithms like linear and logistic regression can have\n",
        "# poor performance if there are highly correlated input variables in your data\n",
        "\n",
        "correlations = data.corr()\n",
        "# Plotting\n",
        "fig = pyplot.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
        "fig.colorbar(cax)\n",
        "ticks = numpy.arange(0, 9, 1)\n",
        "# Specify names for attributes - less generic. Don't specify first, then do so\n",
        "# to investigate more closely\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "ax.set_xticklabels(names)\n",
        "ax.set_yticklabels(names)\n",
        "pyplot.show()\n",
        "\n",
        "# Scatter plot matrix\n",
        "# Look at the pairwise relationships from different perspectives\n",
        "\n",
        "scatter_matrix(data, figsize=[20, 20])\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "RMsFAQhyA9vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation\n",
        "\n",
        "A difficulty is that different algorithms make different assumptions about your data and may require different transforms. Sometimes algorithms can deliver better results without pre-processing.\n",
        "\n",
        "Generally, I would recommend creating many different views and transforms of your data, then exercise a handful of algorithms on each view of your dataset. This will help you to flush out which data transforms might be better at exposing the structure of your problem in general.\n",
        "\n",
        "Two standard idioms for transforming data: fit and multiple transform; combined fit-and-transform.\n"
      ],
      "metadata": {
        "id": "6D7t7BgMPdK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = data.values\n",
        "# Separate array into input and output components\n",
        "X = array[:, 0:8]\n",
        "Y = array[:, 8]\n",
        "\n",
        "# Rescale data\n",
        "# Useful for optimisation algos (used in the core of ML algos) like gradient\n",
        "# descent, algos that weight inputs like regression and neural networks, and\n",
        "# algos that use distance measures like k-Nearest Neighbors\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "# Summarise transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(rescaledX[0:5, :])\n",
        "\n",
        "# Standardise data\n",
        "# Suitable for techniques that assume a Gaussian distribution in the input\n",
        "# variables and work better with rescaled data, such as linear regression,\n",
        "# logistic regression, and linear discriminate analysis\n",
        "\n",
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "# Summarise transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(rescaledX[0:5, :])\n",
        "\n",
        "# Normalise data\n",
        "# Useful for sparse datasets with attributes of varying scales when using\n",
        "# algorithms that weight input values such as neural networks and use distance\n",
        "# measures such as k-Nearest Neighbors\n",
        "\n",
        "scaler = Normalizer().fit(X)\n",
        "normalizedX = scaler.transform(X)\n",
        "# Summarise transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(normalizedX[0:5, :])\n",
        "\n",
        "# Binarise data\n",
        "\n",
        "# Useful when you have probabilities that you want to make crisp values. It is\n",
        "# also useful when feature engineering and you want to add new features that\n",
        "# indicate something meaningful\n",
        "\n",
        "binarizer = Binarizer(threshold=0.0).fit(X)\n",
        "binaryX = binarizer.transform(X)\n",
        "# Summarise transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(binaryX[0:5, :])\n"
      ],
      "metadata": {
        "id": "PI6smqy1PeyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot each attribute and see the changes\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "data.plot(kind='density', subplots=True, layout=(3, 3), sharex=False, figsize=[10, 10])\n",
        "pyplot.show()\n",
        "\n",
        "sns.distplot(rescaledX[:, 1])\n",
        "sns.distplot(rescaledX[:, 2])\n",
        "sns.distplot(rescaledX[:, 3])\n",
        "sns.distplot(rescaledX[:, 4])\n",
        "sns.distplot(rescaledX[:, 5])\n",
        "sns.distplot(rescaledX[:, 6])\n",
        "sns.distplot(rescaledX[:, 7])\n",
        "\n",
        "# Decision tree classification on raw vs normalised data\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "kfold = KFold(n_splits=10, random_state=7, shuffle=None)\n",
        "model = DecisionTreeClassifier()\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"Mean estimated accuracy \\n\",results.mean())\n",
        "results2 = cross_val_score(model, normalizedX, Y, cv=kfold)\n",
        "print(\"Mean estimated accuracy on normalised data \\n\",results2.mean())"
      ],
      "metadata": {
        "id": "_WQze_gwnTYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature selection\n",
        "\n",
        "Having irrelevant features in your data can decrease the accuracy of many models, especially linear algorithms like linear and logistic regression. Benefits: reduces overfitting; improves accuracy; reduces training time.\n"
      ],
      "metadata": {
        "id": "txvPWFxLg5zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = data.values\n",
        "# Separate array into input and output components\n",
        "X = array[:, 0:8]\n",
        "Y = array[:, 8]\n"
      ],
      "metadata": {
        "id": "2uN_QlTUvUU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Univariate Selection\n",
        "\n",
        "Statistical tests can be used to select those features that have the strongest relationship with the output variable.\n"
      ],
      "metadata": {
        "id": "38-CrNbpvX_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select top 4 features with chi-squared test\n",
        "test = SelectKBest(score_func=chi2, k=4)\n",
        "fit = test.fit(X, Y)\n",
        "# Summarise scores\n",
        "set_printoptions(precision=3)\n",
        "print(fit.scores_)\n",
        "features = fit.transform(X)\n",
        "# Summarise selected features\n",
        "print(features[0:5, :])\n"
      ],
      "metadata": {
        "id": "9kHpIBeSvomz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recursive feature elimination\n",
        "\n",
        "The choice of algorithm does not matter too much as long as it is skillful and consistent.\n"
      ],
      "metadata": {
        "id": "6uWZ9UaowIzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select top 3 features with logistic regression\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "rfe = RFE(estimator=model, n_features_to_select=3)\n",
        "fit = rfe.fit(X, Y)\n",
        "print(\"Num Features: %d\" % fit.n_features_)\n",
        "print(\"Selected Features: %s\" % fit.support_)\n",
        "print(\"Feature Ranking: %s\" % fit.ranking_)"
      ],
      "metadata": {
        "id": "X_IDQllVwCuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA\n"
      ],
      "metadata": {
        "id": "CWUmlg2QwS4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=3)\n",
        "fit = pca.fit(X)\n",
        "# Summarise components\n",
        "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
        "print(fit.components_)"
      ],
      "metadata": {
        "id": "yjh_KPjnwU7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature importance\n",
        "\n",
        "Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance of features"
      ],
      "metadata": {
        "id": "ZvO2UQVlwYEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use extra trees classifier\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X, Y)\n",
        "print(model.feature_importances_)\n"
      ],
      "metadata": {
        "id": "kcmN8OEehNtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resampling\n",
        "\n",
        "You need to know how well your algorithms perform on unseen data.\n",
        "\n",
        "The best way to evaluate the performance of an algorithm would be to make predictions for new data to which you already know the answers. The second-best way is to use clever techniques from statistics called resampling methods that allow you to make accurate estimates for how well your algorithm will perform on new data.\n",
        "\n",
        "Generally k-fold cross-validation is the gold standard for evaluating the performance of a machine learning algorithm on unseen data with k set to 3, 5, or 10.\n",
        "\n",
        "Using a train/test split is good for speed when using a slow algorithm and produces performance estimates with lower bias when using large datasets.\n",
        "\n",
        "Techniques like leave-one-out cross-validation and repeated random splits can be useful intermediates when trying to balance variance in the estimated performance, model training speed, and dataset size.\n",
        "\n",
        "Experiment and find a technique for your problem that is fast and produces reasonable estimates of performance that you can use to make decisions. If in doubt, use 10-fold cross-validation.\n"
      ],
      "metadata": {
        "id": "ngg-gJ4tSRxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = data.values\n",
        "# Separate array into input and output components\n",
        "X = array[:, 0:8]\n",
        "Y = array[:, 8]\n"
      ],
      "metadata": {
        "id": "eUAdvG9mwzqK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into train and test sets\n",
        "\n",
        "Hyperparameters: ratio of train:test set\n",
        "\n",
        "Very fast, hence useful to use this approach when the algorithm you are investigating is slow to train. Ideal for large datasets (millions of records) where there is strong evidence that both splits of the data are representative of the underlying problem. Produces performance estimates with lower bias when using large datasets.\n",
        "\n",
        "A downside of this technique is that it can have a high variance. This means that differences in the training and test dataset can result in meaningful differences in the estimate of accuracy.\n"
      ],
      "metadata": {
        "id": "Yrz43v2YwpeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 0.33\n",
        "seed = 7\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
        "random_state=seed)\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, Y_train)\n",
        "result = model.score(X_test, Y_test)\n",
        "print(\"Accuracy: %.3f%%\" % (result * 100.0))\n"
      ],
      "metadata": {
        "id": "zUi5voPpSqTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-fold cross validation\n",
        "\n",
        "Hyperparameters: Choice of k must allow the size of each test partition to be large enough to be a reasonable sample of the problem, whilst allowing enough repetitions of the train-test evaluation of the algorithm to provide a fair estimate of the algorithm's performance on unseen data. For modest sized datasets in the thousands or tens of thousands of records, k values of 3, 5, and 10 are common.\n",
        "\n",
        "Estimate the performance of a machine learning algorithm with less variance than a single train-test set split. The result is a more reliable estimate of the performance of the algorithm on new data.\n"
      ],
      "metadata": {
        "id": "9Ynj5o2Ww1H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_folds = 10\n",
        "seed = 7\n",
        "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
      ],
      "metadata": {
        "id": "XDBE3swZw5kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leave one out cross validation\n",
        "\n",
        "The result is a large number of performance measures that can be summarised in an effort to give a more reasonable estimate of the accuracy of your model on unseen data.\n",
        "\n",
        "A downside is that it can be a computationally more expensive procedure than k-fold cross-validation.\n"
      ],
      "metadata": {
        "id": "0gXOdkB0yvzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loocv = LeaveOneOut()\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "results = cross_val_score(model, X, Y, cv=loocv)\n",
        "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))\n"
      ],
      "metadata": {
        "id": "ft9s6cr1zvuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeated random test-train splits\n",
        "\n",
        "This has the speed of using a train/test split and the reduction in\n",
        "variance in the estimated performance of k-fold cross-validation. You can also repeat the process many more times as needed to improve the accuracy.\n",
        "\n",
        "A down side is that repetitions may include much of the same data in the train or the test split from run to run, introducing redundancy into the evaluation.\n"
      ],
      "metadata": {
        "id": "DmuAVkTr0vAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_splits = 10\n",
        "test_size = 0.33\n",
        "seed = 7\n",
        "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))\n"
      ],
      "metadata": {
        "id": "NQNwu3xN1MBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "MwOGFs_VG3JW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}