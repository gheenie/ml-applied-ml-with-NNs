{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqBrd/Ssz8HKGNYPEQ480S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gheenie/msc-applied-ml/blob/main/lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "from google.colab import drive\n",
        "import numpy\n",
        "from numpy import loadtxt\n",
        "# from urllib import urlopen\n",
        "from pandas import read_csv\n",
        "from pandas import set_option\n",
        "from matplotlib import pyplot\n",
        "from pandas.plotting import scatter_matrix\n",
        "from numpy import set_printoptions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import Binarizer\n"
      ],
      "metadata": {
        "id": "eArvgqGpLsRe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount location\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change working dir\n",
        "os.chdir('drive/Colab Notebooks')\n"
      ],
      "metadata": {
        "id": "-3a5VjGFGr8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ],
      "metadata": {
        "id": "XTQZt2UcKfyG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57LggRch-e0-"
      },
      "outputs": [],
      "source": [
        "# Load CSV Using Python Standard Library\n",
        "\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "raw_data = open(filename, 'rt')\n",
        "reader = csv.reader(raw_data, delimiter=',', quoting=csv.QUOTE_NONE)\n",
        "x = list(reader)\n",
        "data = numpy.array(x).astype('float')\n",
        "print(data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV using NumPy\n",
        "\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "raw_data = open(filename, 'rt')\n",
        "data = loadtxt(raw_data, delimiter=\",\")\n",
        "print(data.shape)\n"
      ],
      "metadata": {
        "id": "WiF-RPLiI4Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV from URL using NumPy\n",
        "\n",
        "url = 'https://goo.gl/XXXXX'\n",
        "raw_data = urlopen(url)\n",
        "dataset = loadtxt(raw_data, delimiter=\",\")\n",
        "print(dataset.shape)\n"
      ],
      "metadata": {
        "id": "Fy4H-EZ-JhV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV using Pandas\n",
        "\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "data = read_csv(filename, names=names)\n",
        "print(data.shape)\n"
      ],
      "metadata": {
        "id": "WzZ8rWNIKaw7",
        "outputId": "8c01f6a0-809a-413c-8a85-00a2f04c70cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV using Pandas from URL\n",
        "\n",
        "url = 'https://goo.gl/XXXXXXX'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "data = read_csv(url, names=names)\n",
        "print(data.shape)\n"
      ],
      "metadata": {
        "id": "rs89yhlHLHbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descriptive statistics"
      ],
      "metadata": {
        "id": "uoR6YUvoNRp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect data\n",
        "\n",
        "# First few rows\n",
        "peek = data.head(20)\n",
        "print(peek)\n",
        "# Data types\n",
        "types = data.dtypes\n",
        "print(types)\n",
        "\n",
        "# Review data dimensions\n",
        "# Too many or few rows or features?\n",
        "\n",
        "shape = data.shape\n",
        "print(shape)\n",
        "\n",
        "# Descriptive stats\n",
        "\n",
        "set_option('display.width', 100)\n",
        "set_option('display.precision', 3)\n",
        "description = data.describe()\n",
        "print(description)\n",
        "\n",
        "# Class distributions (for classification probs)\n",
        "# Need to be balanced\n",
        "\n",
        "class_counts = data.groupby('class').size()\n",
        "print(class_counts)\n",
        "\n",
        "# Pairwise Pearson correlations\n",
        "# Don't want highly correlated pairs\n",
        "\n",
        "correlations = data.corr(method='pearson')\n",
        "print(correlations)\n",
        "\n",
        "# Skew of univariate distributions for each attribute\n",
        "\n",
        "skew = data.skew()\n",
        "print(skew)\n"
      ],
      "metadata": {
        "id": "jlV2q4QRNTWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualisation"
      ],
      "metadata": {
        "id": "OYYTstvfA6NO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Univariate plots\n",
        "# Understand each attribute of your dataset independently\n",
        "\n",
        "# Univariate histograms\n",
        "# Get an idea of distributions.\n",
        "# From the shape of the bins you can quickly get a\n",
        "# feeling for whether an attribute is Gaussian, skewed or even has an\n",
        "# exponential distribution. It can also help you see possible outliers.\n",
        "\n",
        "data.hist()\n",
        "pyplot.show()\n",
        "\n",
        "# Univariate density plots\n",
        "# Get an idea of distributions\n",
        "\n",
        "data.plot(kind='density', subplots=True, layout=(3,3), sharex=False)\n",
        "pyplot.show()\n",
        "\n",
        "# Box and whiskers plot\n",
        "# Get an idea of distributions.\n",
        "# Candidate outlier values are 1.5 times greater than the size of spread of\n",
        "# the middle 50% of the data\n",
        "\n",
        "data.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\n",
        "pyplot.show()\n",
        "\n",
        "# Multivariate plots\n",
        "# Show the interactions between multiple variables in your dataset\n",
        "\n",
        "# Correlation matrix plot\n",
        "# Some machine learning algorithms like linear and logistic regression can have\n",
        "# poor performance if there are highly correlated input variables in your data\n",
        "\n",
        "correlations = data.corr()\n",
        "# Plotting\n",
        "fig = pyplot.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
        "fig.colorbar(cax)\n",
        "ticks = numpy.arange(0, 9, 1)\n",
        "# Specify names for attributes - less generic. Don't specify first, then do so\n",
        "# to investigate more closely\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "ax.set_xticklabels(names)\n",
        "ax.set_yticklabels(names)\n",
        "pyplot.show()\n",
        "\n",
        "# Scatter plot matrix\n",
        "# Look at the pairwise relationships from different perspectives\n",
        "\n",
        "scatter_matrix(data, figsize=[20, 20])\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "RMsFAQhyA9vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation\n",
        "\n",
        "A difficulty is that different algorithms make different assumptions about your data and may require different transforms. Sometimes algorithms can deliver better results without pre-processing.\n",
        "\n",
        "Generally, I would recommend creating many different views and transforms of your data, then exercise a handful of algorithms on each view of your dataset. This will help you to flush out which data transforms might be better at exposing the structure of your problem in general.\n",
        "\n",
        "Two standard idioms for transforming data: fit and multiple transform; combined fit-and-transform."
      ],
      "metadata": {
        "id": "6D7t7BgMPdK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = data.values\n",
        "# Separate array into input and output components\n",
        "X = array[:, 0:8]\n",
        "Y = array[:, 8]\n",
        "\n",
        "# Rescale data\n",
        "# Useful for optimisation algos (used in the core of ML algos) like gradient\n",
        "# descent, algos that weight inputs like regression and neural networks, and\n",
        "# algos that use distance measures like k-Nearest Neighbors\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "# Summarise transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(rescaledX[0:5, :])\n",
        "\n",
        "# Standardise data\n",
        "# Suitable for techniques that assume a Gaussian distribution in the input\n",
        "# variables and work better with rescaled data, such as linear regression,\n",
        "# logistic regression, and linear discriminate analysis\n",
        "\n",
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "# Summarise transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(rescaledX[0:5, :])\n",
        "\n",
        "# Normalise data\n",
        "# Useful for sparse datasets with attributes of varying scales when using\n",
        "# algorithms that weight input values such as neural networks and use distance\n",
        "# measures such as k-Nearest Neighbors\n",
        "\n",
        "scaler = Normalizer().fit(X)\n",
        "normalizedX = scaler.transform(X)\n",
        "# Summarise transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(normalizedX[0:5, :])\n",
        "\n",
        "# Binarise data\n",
        "\n",
        "# Useful when you have probabilities that you want to make crisp values. It is\n",
        "# also useful when feature engineering and you want to add new features that\n",
        "# indicate something meaningful\n",
        "\n",
        "binarizer = Binarizer(threshold=0.0).fit(X)\n",
        "binaryX = binarizer.transform(X)\n",
        "# Summarise transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(binaryX[0:5, :])\n"
      ],
      "metadata": {
        "id": "PI6smqy1PeyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot each attribute and see the changes\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "data.plot(kind='density', subplots=True, layout=(3, 3), sharex=False, figsize=[10, 10])\n",
        "pyplot.show()\n",
        "\n",
        "sns.distplot(rescaledX[:, 1])\n",
        "sns.distplot(rescaledX[:, 2])\n",
        "sns.distplot(rescaledX[:, 3])\n",
        "sns.distplot(rescaledX[:, 4])\n",
        "sns.distplot(rescaledX[:, 5])\n",
        "sns.distplot(rescaledX[:, 6])\n",
        "sns.distplot(rescaledX[:, 7])\n",
        "\n",
        "# Decision tree classification on raw vs normalised data\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "kfold = KFold(n_splits=10, random_state=7, shuffle=None)\n",
        "model = DecisionTreeClassifier()\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"Mean estimated accuracy \\n\",results.mean())\n",
        "results2 = cross_val_score(model, normalizedX, Y, cv=kfold)\n",
        "print(\"Mean estimated accuracy on normalised data \\n\",results2.mean())"
      ],
      "metadata": {
        "id": "_WQze_gwnTYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature selection and resampling"
      ],
      "metadata": {
        "id": "txvPWFxLg5zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "MwOGFs_VG3JW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}