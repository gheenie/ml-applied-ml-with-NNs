{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtsV3QBvAlnXtkgCSZJgzC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gheenie/ml-applied-ml-with-NNs/blob/main/lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "from google.colab import drive\n",
        "import numpy\n",
        "from numpy import loadtxt\n",
        "# from urllib import urlopen\n",
        "from pandas import read_csv\n",
        "from pandas import set_option\n",
        "from matplotlib import pyplot\n",
        "from pandas.plotting import scatter_matrix\n",
        "from numpy import set_printoptions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import LeaveOneOut\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.tree import export_graphviz\n",
        "from subprocess import check_call\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.pipeline import Pipeline\n"
      ],
      "metadata": {
        "id": "eArvgqGpLsRe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount location\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change working dir\n",
        "os.chdir('drive/Colab Notebooks')\n"
      ],
      "metadata": {
        "id": "-3a5VjGFGr8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data\n"
      ],
      "metadata": {
        "id": "XTQZt2UcKfyG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57LggRch-e0-"
      },
      "outputs": [],
      "source": [
        "# Load CSV Using Python Standard Library\n",
        "\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "raw_data = open(filename, 'rt')\n",
        "reader = csv.reader(raw_data, delimiter=',', quoting=csv.QUOTE_NONE)\n",
        "x = list(reader)\n",
        "data = numpy.array(x).astype('float')\n",
        "print(data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV using NumPy\n",
        "\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "raw_data = open(filename, 'rt')\n",
        "data = loadtxt(raw_data, delimiter=\",\")\n",
        "print(data.shape)\n"
      ],
      "metadata": {
        "id": "WiF-RPLiI4Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV from URL using NumPy\n",
        "\n",
        "url = 'https://goo.gl/XXXXX'\n",
        "raw_data = urlopen(url)\n",
        "dataset = loadtxt(raw_data, delimiter=\",\")\n",
        "print(dataset.shape)\n"
      ],
      "metadata": {
        "id": "Fy4H-EZ-JhV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV using Pandas\n",
        "\n",
        "filename = 'pima-indians-diabetes.data.csv'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "data = read_csv(filename, names=names)\n",
        "print(data.shape)\n"
      ],
      "metadata": {
        "id": "WzZ8rWNIKaw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51ab35c9-2f21-4a1c-cc1b-abcd650c1969"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV using Pandas from URL\n",
        "\n",
        "url = 'https://goo.gl/XXXXXXX'\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "data = read_csv(url, names=names)\n",
        "print(data.shape)\n"
      ],
      "metadata": {
        "id": "rs89yhlHLHbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descriptive statistics\n"
      ],
      "metadata": {
        "id": "uoR6YUvoNRp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect data\n",
        "\n",
        "# First few rows\n",
        "peek = data.head(20)\n",
        "print(peek)\n",
        "# Data types\n",
        "types = data.dtypes\n",
        "print(types)\n",
        "\n",
        "# Review data dimensions\n",
        "# Too many or few rows or features?\n",
        "\n",
        "shape = data.shape\n",
        "print(shape)\n",
        "\n",
        "# Descriptive stats\n",
        "\n",
        "set_option('display.width', 100)\n",
        "set_option('display.precision', 3)\n",
        "description = data.describe()\n",
        "print(description)\n",
        "\n",
        "# Class distributions (for classification probs)\n",
        "# Need to be balanced\n",
        "\n",
        "class_counts = data.groupby('class').size()\n",
        "print(class_counts)\n",
        "\n",
        "# Pairwise Pearson correlations\n",
        "# Don't want highly correlated pairs\n",
        "\n",
        "correlations = data.corr(method='pearson')\n",
        "print(correlations)\n",
        "\n",
        "# Skew of univariate distributions for each attribute\n",
        "\n",
        "skew = data.skew()\n",
        "print(skew)\n"
      ],
      "metadata": {
        "id": "jlV2q4QRNTWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualisation\n"
      ],
      "metadata": {
        "id": "OYYTstvfA6NO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Univariate plots\n",
        "# Understand each attribute of your dataset independently\n",
        "\n",
        "# Univariate histograms\n",
        "# Get an idea of distributions.\n",
        "# From the shape of the bins you can quickly get a\n",
        "# feeling for whether an attribute is Gaussian, skewed or even has an\n",
        "# exponential distribution. It can also help you see possible outliers.\n",
        "\n",
        "data.hist()\n",
        "pyplot.show()\n",
        "\n",
        "# Univariate density plots\n",
        "# Get an idea of distributions\n",
        "\n",
        "data.plot(kind='density', subplots=True, layout=(3,3), sharex=False)\n",
        "pyplot.show()\n",
        "\n",
        "# Box and whiskers plot\n",
        "# Get an idea of distributions.\n",
        "# Candidate outlier values are 1.5 times greater than the size of spread of\n",
        "# the middle 50% of the data\n",
        "\n",
        "data.plot(kind='box', subplots=True, layout=(3,3), sharex=False, sharey=False)\n",
        "pyplot.show()\n",
        "\n",
        "# Multivariate plots\n",
        "# Show the interactions between multiple variables in your dataset\n",
        "\n",
        "# Correlation matrix plot\n",
        "# Some machine learning algorithms like linear and logistic regression can have\n",
        "# poor performance if there are highly correlated input variables in your data\n",
        "\n",
        "correlations = data.corr()\n",
        "# Plotting\n",
        "fig = pyplot.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
        "fig.colorbar(cax)\n",
        "ticks = numpy.arange(0, 9, 1)\n",
        "# Specify names for attributes - less generic. Don't specify first, then do so\n",
        "# to investigate more closely\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "ax.set_xticklabels(names)\n",
        "ax.set_yticklabels(names)\n",
        "pyplot.show()\n",
        "\n",
        "# Scatter plot matrix\n",
        "# Look at the pairwise relationships from different perspectives\n",
        "\n",
        "scatter_matrix(data, figsize=[20, 20])\n",
        "pyplot.show()"
      ],
      "metadata": {
        "id": "RMsFAQhyA9vm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation\n"
      ],
      "metadata": {
        "id": "6D7t7BgMPdK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A difficulty is that different algorithms make different assumptions about your data and may require different transforms. Sometimes algorithms can deliver better results without pre-processing.\n",
        "\n",
        "Generally, I would recommend creating many different views and transforms of your data, then exercise a handful of algorithms on each view of your dataset. This will help you to flush out which data transforms might be better at exposing the structure of your problem in general.\n",
        "\n",
        "Two standard idioms for transforming data: fit and multiple transform; combined fit-and-transform.\n"
      ],
      "metadata": {
        "id": "-Mvd619NPqvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = data.values\n",
        "# Separate array into input and output components\n",
        "X = array[:, 0:8]\n",
        "Y = array[:, 8]\n"
      ],
      "metadata": {
        "id": "Gz6c_C3U3T1_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rescale data\n",
        "\n",
        "Useful for optimisation algos (used in the core of ML algos) like gradient descent, algos that weight inputs like regression and neural networks, and algos that use distance measures like k-Nearest Neighbors.\n"
      ],
      "metadata": {
        "id": "XyLdH-jj3XC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "# Summarise transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(rescaledX[0:5, :])\n"
      ],
      "metadata": {
        "id": "5BqAySSY3gD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardise data\n",
        "\n",
        "Suitable for techniques that assume a Gaussian distribution in the input variables and work better with rescaled data, such as linear regression, logistic regression, and linear discriminate analysis.\n"
      ],
      "metadata": {
        "id": "ZvRDd6zm3ix5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "# Summarise transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(rescaledX[0:5, :])\n"
      ],
      "metadata": {
        "id": "uUdNsD593oVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalise data\n",
        "\n",
        "Useful for sparse datasets with attributes of varying scales when using algorithms that weight input values such as neural networks and use distance measures such as k-Nearest Neighbors."
      ],
      "metadata": {
        "id": "jLAWSiLh3ucV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = Normalizer().fit(X)\n",
        "normalizedX = scaler.transform(X)\n",
        "# Summarise transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(normalizedX[0:5, :])\n"
      ],
      "metadata": {
        "id": "0U1HxlHs3zQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binarise data\n",
        "\n",
        "Useful when you have probabilities that you want to make crisp values. It is also useful when feature engineering and you want to add new features that indicate something meaningful"
      ],
      "metadata": {
        "id": "eeFWSHPH31LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "binarizer = Binarizer(threshold=0.0).fit(X)\n",
        "binaryX = binarizer.transform(X)\n",
        "# Summarise transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(binaryX[0:5, :])\n"
      ],
      "metadata": {
        "id": "PI6smqy1PeyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot each attribute and see the changes\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "data.plot(kind='density', subplots=True, layout=(3, 3), sharex=False, figsize=[10, 10])\n",
        "pyplot.show()\n",
        "\n",
        "sns.distplot(rescaledX[:, 1])\n",
        "sns.distplot(rescaledX[:, 2])\n",
        "sns.distplot(rescaledX[:, 3])\n",
        "sns.distplot(rescaledX[:, 4])\n",
        "sns.distplot(rescaledX[:, 5])\n",
        "sns.distplot(rescaledX[:, 6])\n",
        "sns.distplot(rescaledX[:, 7])\n",
        "\n",
        "# Decision tree classification on raw vs normalised data\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "kfold = KFold(n_splits=10, random_state=7, shuffle=None)\n",
        "model = DecisionTreeClassifier()\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"Mean estimated accuracy \\n\",results.mean())\n",
        "results2 = cross_val_score(model, normalizedX, Y, cv=kfold)\n",
        "print(\"Mean estimated accuracy on normalised data \\n\",results2.mean())"
      ],
      "metadata": {
        "id": "_WQze_gwnTYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature selection\n"
      ],
      "metadata": {
        "id": "txvPWFxLg5zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having irrelevant features in your data can decrease the accuracy of many models, especially linear algorithms like linear and logistic regression. Benefits: reduces overfitting; improves accuracy; reduces training time.\n"
      ],
      "metadata": {
        "id": "ifbcvr7kPiPW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = data.values\n",
        "# Separate array into input and output components\n",
        "X = array[:, 0:8]\n",
        "Y = array[:, 8]\n"
      ],
      "metadata": {
        "id": "2uN_QlTUvUU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Univariate Selection\n",
        "\n",
        "Statistical tests can be used to select those features that have the strongest relationship with the output variable.\n"
      ],
      "metadata": {
        "id": "38-CrNbpvX_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select top 4 features with chi-squared test\n",
        "test = SelectKBest(score_func=chi2, k=4)\n",
        "fit = test.fit(X, Y)\n",
        "# Summarise scores\n",
        "set_printoptions(precision=3)\n",
        "print(fit.scores_)\n",
        "features = fit.transform(X)\n",
        "# Summarise selected features\n",
        "print(features[0:5, :])\n"
      ],
      "metadata": {
        "id": "9kHpIBeSvomz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recursive feature elimination\n",
        "\n",
        "The choice of algorithm does not matter too much as long as it is skillful and consistent.\n"
      ],
      "metadata": {
        "id": "6uWZ9UaowIzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select top 3 features with logistic regression\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "rfe = RFE(estimator=model, n_features_to_select=3)\n",
        "fit = rfe.fit(X, Y)\n",
        "print(\"Num Features: %d\" % fit.n_features_)\n",
        "print(\"Selected Features: %s\" % fit.support_)\n",
        "print(\"Feature Ranking: %s\" % fit.ranking_)"
      ],
      "metadata": {
        "id": "X_IDQllVwCuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA\n"
      ],
      "metadata": {
        "id": "CWUmlg2QwS4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=3)\n",
        "fit = pca.fit(X)\n",
        "# Summarise components\n",
        "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
        "print(fit.components_)"
      ],
      "metadata": {
        "id": "yjh_KPjnwU7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature importance\n",
        "\n",
        "Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance of features"
      ],
      "metadata": {
        "id": "ZvO2UQVlwYEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use extra trees classifier\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X, Y)\n",
        "print(model.feature_importances_)\n"
      ],
      "metadata": {
        "id": "kcmN8OEehNtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resampling\n"
      ],
      "metadata": {
        "id": "ngg-gJ4tSRxK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You need to know how well your algorithms perform on unseen data.\n",
        "\n",
        "The best way to evaluate the performance of an algorithm would be to make predictions for new data to which you already know the answers. The second-best way is to use clever techniques from statistics called resampling methods that allow you to make accurate estimates for how well your algorithm will perform on new data.\n",
        "\n",
        "Generally k-fold cross-validation is the gold standard for evaluating the performance of a machine learning algorithm on unseen data with k set to 3, 5, or 10.\n",
        "\n",
        "Using a train/test split is good for speed when using a slow algorithm and produces performance estimates with lower bias when using large datasets.\n",
        "\n",
        "Techniques like leave-one-out cross-validation and repeated random splits can be useful intermediates when trying to balance variance in the estimated performance, model training speed, and dataset size.\n",
        "\n",
        "Experiment and find a technique for your problem that is fast and produces reasonable estimates of performance that you can use to make decisions. If in doubt, use 10-fold cross-validation.\n"
      ],
      "metadata": {
        "id": "XwdSTo9C-lCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = data.values\n",
        "# Separate array into input and output components\n",
        "X = array[:, 0:8]\n",
        "Y = array[:, 8]\n"
      ],
      "metadata": {
        "id": "eUAdvG9mwzqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split into train and test sets\n",
        "\n",
        "Hyperparameters: ratio of train:test set\n",
        "\n",
        "Very fast, hence useful to use this approach when the algorithm you are investigating is slow to train. Ideal for large datasets (millions of records) where there is strong evidence that both splits of the data are representative of the underlying problem. Produces performance estimates with lower bias when using large datasets.\n",
        "\n",
        "A downside of this technique is that it can have a high variance. This means that differences in the training and test dataset can result in meaningful differences in the estimate of accuracy.\n"
      ],
      "metadata": {
        "id": "Yrz43v2YwpeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 0.33\n",
        "seed = 7\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
        "random_state=seed)\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, Y_train)\n",
        "result = model.score(X_test, Y_test)\n",
        "print(\"Accuracy: %.3f%%\" % (result * 100.0))\n"
      ],
      "metadata": {
        "id": "zUi5voPpSqTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-fold cross validation\n",
        "\n",
        "Hyperparameters: Choice of k must allow the size of each test partition to be large enough to be a reasonable sample of the problem, whilst allowing enough repetitions of the train-test evaluation of the algorithm to provide a fair estimate of the algorithm's performance on unseen data. For modest sized datasets in the thousands or tens of thousands of records, k values of 3, 5, and 10 are common.\n",
        "\n",
        "Estimate the performance of a machine learning algorithm with less variance than a single train-test set split. The result is a more reliable estimate of the performance of the algorithm on new data.\n"
      ],
      "metadata": {
        "id": "9Ynj5o2Ww1H3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_folds = 10\n",
        "seed = 7\n",
        "kfold = KFold(n_splits=num_folds, random_state=seed, shuffle=True)\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))"
      ],
      "metadata": {
        "id": "XDBE3swZw5kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leave one out cross validation\n",
        "\n",
        "The result is a large number of performance measures that can be summarised in an effort to give a more reasonable estimate of the accuracy of your model on unseen data.\n",
        "\n",
        "A downside is that it can be a computationally more expensive procedure than k-fold cross-validation.\n"
      ],
      "metadata": {
        "id": "0gXOdkB0yvzS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loocv = LeaveOneOut()\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "results = cross_val_score(model, X, Y, cv=loocv)\n",
        "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))\n"
      ],
      "metadata": {
        "id": "ft9s6cr1zvuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeated random test-train splits\n",
        "\n",
        "This has the speed of using a train/test split and the reduction in\n",
        "variance in the estimated performance of k-fold cross-validation. You can also repeat the process many more times as needed to improve the accuracy.\n",
        "\n",
        "A down side is that repetitions may include much of the same data in the train or the test split from run to run, introducing redundancy into the evaluation.\n"
      ],
      "metadata": {
        "id": "DmuAVkTr0vAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_splits = 10\n",
        "test_size = 0.33\n",
        "seed = 7\n",
        "kfold = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))\n"
      ],
      "metadata": {
        "id": "NQNwu3xN1MBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation metrics\n"
      ],
      "metadata": {
        "id": "PG7CbuoBcSma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = data.values\n",
        "X = array[:, 0:8]\n",
        "Y = array[:, 8]\n"
      ],
      "metadata": {
        "id": "bHXybmbY5ZZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification metrics\n",
        "\n",
        "Demonstrated with logistic regression and 10-fold cross-validation.\n"
      ],
      "metadata": {
        "id": "9jGHYzbu5qMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification accuracy\n",
        "\n",
        "Most common but most misused. It is really only suitable when there are an equal number of observations in each class (which is rarely the case) and that all predictions and prediction errors are equally important, which is often not the case.\n"
      ],
      "metadata": {
        "id": "EPQfXrkH50Ss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "scoring = 'accuracy'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"Accuracy: %.3f (%.3f)\" % (results.mean(), results.std()))\n"
      ],
      "metadata": {
        "id": "-sbmvkuL6dnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logarithmic loss\n"
      ],
      "metadata": {
        "id": "d9sOjjBG_a3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "scoring = 'neg_log_loss'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"Logloss: %.3f (%.3f)\" % (results.mean(), results.std()))\n"
      ],
      "metadata": {
        "id": "JHvHNgWz_c-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Area under ROC curve\n"
      ],
      "metadata": {
        "id": "czoGPnXIKbSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "scoring = 'roc_auc'\n",
        "results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "print(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))\n",
        "\n",
        "# split into train/test sets\n",
        "trainX, testX, trainy, testy = train_test_split(X, Y, test_size=0.1, random_state=2)\n",
        "# fit a model\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(trainX, trainy)\n",
        "# predict probabilities\n",
        "probs = model.predict_proba(testX)\n",
        "# keep probabilities for the positive outcome only\n",
        "probs = probs[:, 1]\n",
        "# calculate AUC\n",
        "auc = roc_auc_score(testy, probs)\n",
        "print('AUC: %.3f' % auc)\n",
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(testy, probs)\n",
        "# plot no skill\n",
        "pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
        "# plot the roc curve for the model\n",
        "pyplot.plot(fpr, tpr, marker='.')\n",
        "# show the plot\n",
        "pyplot.show()\n"
      ],
      "metadata": {
        "id": "NvKhE59BKdz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix\n",
        "\n",
        "A handy presentation of the accuracy of a model with two or more classes.\n"
      ],
      "metadata": {
        "id": "Sg9kK2QXhqWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 0.33\n",
        "seed = 7\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
        "random_state=seed)\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, Y_train)\n",
        "predicted = model.predict(X_test)\n",
        "matrix = confusion_matrix(Y_test, predicted)\n",
        "print(matrix)\n"
      ],
      "metadata": {
        "id": "A-3unxY_idl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification report\n"
      ],
      "metadata": {
        "id": "XesjRyQNk85U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_size = 0.33\n",
        "seed = 7\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
        "random_state=seed)\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "model.fit(X_train, Y_train)\n",
        "predicted = model.predict(X_test)\n",
        "report = classification_report(Y_test, predicted)\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "QCuOHavqk_ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algo shortlisting\n"
      ],
      "metadata": {
        "id": "BufJwRKWmsi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You cannot know which algorithm will work best on your dataset beforehand. You must use trial and error to discover a shortlist of algorithms that do well on your problem that you can then double down on and tune further. The question is not: What algorithm should I use on my dataset? Instead it is: What algorithms\n",
        "should I spot-check on my dataset? You can guess at what algorithms might do well on your dataset, and this can be a good starting point. I recommend trying a mixture of algorithms and see what is good at picking out the structure in your data. Some suggestions when spotchecking algorithms on your dataset:\n",
        "• Try a mixture of algorithm representations (e.g. instances and trees).\n",
        "• Try a mixture of learning algorithms (e.g. different algorithms for learning the same type of\n",
        "representation).\n",
        "• Try a mixture of modelling types (e.g. linear and nonlinear functions or parametric and\n",
        "nonparametric).\n"
      ],
      "metadata": {
        "id": "sR3h8VRRpwD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = data.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n"
      ],
      "metadata": {
        "id": "-f4BdHRzsH5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression\n",
        "\n",
        "Assumes a Gaussian distribution for the numeric input variables and can model binary classification problems.\n"
      ],
      "metadata": {
        "id": "JKXIJh1brqZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_folds = 10\n",
        "kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())\n"
      ],
      "metadata": {
        "id": "tb7SEyoZmzH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-nearest neighbours\n",
        "\n",
        "Uses a distance metric to find the k most similar instances in the training data for a new instance and takes the mean outcome of the neighbors as the prediction.\n"
      ],
      "metadata": {
        "id": "GOdvO3PNsXfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_folds = 10\n",
        "kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
        "model = KNeighborsClassifier()\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())\n"
      ],
      "metadata": {
        "id": "zfuGMCkcsdte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support vector machines\n",
        "\n",
        "Of particular importance is the use of different kernel functions via the kernel parameter. A powerful Radial Basis Function is used by default.\n"
      ],
      "metadata": {
        "id": "NwBK0wtR7azL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
        "model = SVC()\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())\n"
      ],
      "metadata": {
        "id": "RHLDt-8t7ccX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification and regression trees ie decision trees\n",
        "\n",
        "Decision-tree learners can create over-complex trees that do not generalise the data well ie overfitting. Mechanisms such as pruning (not currently supported), setting the minimum number of samples required at a leaf node, or setting the maximum depth of the tree are necessary to avoid this problem.\n"
      ],
      "metadata": {
        "id": "UcEvYgnQ8rxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_decision_tree(model):\n",
        "    test_size = 0.1\n",
        "    seed = 7\n",
        "    # split into train/test sets\n",
        "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size,\n",
        "    random_state=seed)\n",
        "    # fit a model\n",
        "    model.fit(X_train, Y_train)\n",
        "    predicted = model.predict(X_test)\n",
        "    report = classification_report(Y_test, predicted)\n",
        "    print(report)\n",
        "\n",
        "    export_graphviz(\n",
        "        model,\n",
        "        out_file='pima_tree.dot',\n",
        "        feature_names=names[0:8],\n",
        "        rounded=True,\n",
        "        filled=True\n",
        "    )\n",
        "\n",
        "    # convert .dot to .png\n",
        "    check_call(['dot','-Tpng','pima_tree.dot','-o','pima_tree.png'])\n",
        "    # if pydot is installed use the below\n",
        "    !dot -Tpng pima_tree.dot -o pima_tree.png -Gdpi-600\n",
        "    # display in python\n",
        "    pyplot.figure(figsize = (14, 18))\n",
        "    pyplot.imshow(pyplot.imread('pima_tree.png'))\n",
        "    pyplot.axis('off');\n",
        "    pyplot.show();\n",
        "\n",
        "\n",
        "run_decision_tree(DecisionTreeClassifier())\n",
        "# With pruning\n",
        "run_decision_tree(DecisionTreeClassifier(max_depth=3, min_samples_split=10))\n"
      ],
      "metadata": {
        "id": "XP5Dnj5v8x72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algo comparing\n"
      ],
      "metadata": {
        "id": "lJTXqcpjQNEm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You often end up with multiple good models to choose from. Each model will have different performance characteristics.\n",
        "\n",
        "Time to bring in previous sections. Use resampling to estimate how accurate each model may be on unseen data. Also use a number of different ways of looking at the estimated accuracy (You visualised new data using different techniques in order to look at the data from different perspectives. Now the same idea applies to model selection.). Then choose one or two best models from the suite of models that you have created.\n",
        "\n",
        "The key to a fair comparison of machine learning algorithms is ensuring that each algorithm is evaluated in the same way on the same data. You can achieve this by forcing each algorithm to be evaluated on a consistent test harness and configuring with the same random seed.\n",
        "\n",
        "A way to do this is to use visualisation methods to show the average accuracy, variance, and other properties of the distribution of model accuracies.\n"
      ],
      "metadata": {
        "id": "bejZDicpQ5g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = data.values\n",
        "X = array[:,0:8]\n",
        "Y = array[:,8]\n",
        "\n",
        "# prepare models\n",
        "models = []\n",
        "models.append(('LR', LogisticRegression(solver='liblinear')))\n",
        "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
        "models.append(('KNN', KNeighborsClassifier()))\n",
        "models.append(('CART', DecisionTreeClassifier()))\n",
        "models.append(('NB', GaussianNB()))\n",
        "models.append(('SVM', SVC()))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in models:\n",
        "    kfold = KFold(n_splits=10, random_state=7,shuffle=True)\n",
        "    cv_results = cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
        "    results.append(cv_results)\n",
        "    names.append(name)\n",
        "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "    print(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = pyplot.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "pyplot.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "pyplot.show()\n"
      ],
      "metadata": {
        "id": "n5nYpaDJQVHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipelining\n"
      ],
      "metadata": {
        "id": "o2nPkNnHxsVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array = data.values\n",
        "# Separate array into input and output components\n",
        "X = array[:, 0:8]\n",
        "Y = array[:, 8]\n"
      ],
      "metadata": {
        "id": "G-hTudybyPjt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimators = []\n",
        "# Create a tuple with two elements, a label (standardize) and the instance\n",
        "# StandardScaler.\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('lda', LinearDiscriminantAnalysis()))\n",
        "model = Pipeline(estimators)\n",
        "\n",
        "# Evaluate pipeline.\n",
        "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
        "results = cross_val_score(model, X, Y, cv=kfold)\n",
        "print(results.mean())"
      ],
      "metadata": {
        "id": "pb8vSedLxwN5",
        "outputId": "7d538a2f-57f5-49b2-f3d5-d0d5b43c4830",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7669685577580315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Teardown\n"
      ],
      "metadata": {
        "id": "2fz2ykm4mogI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "MwOGFs_VG3JW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}